{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Chain Pulse\"\n",
        "author: \"Alex Schaef, Nathaniel Hamilton Thompson, Orin Crouse\"\n",
        "date: December 15th, 2022\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    code-tools: true\n",
        "editor: visual\n",
        "execute: \n",
        "  echo: false\n",
        "---"
      ],
      "id": "a90eb41c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 style=\"text-align: center;\">\n",
        "\n",
        "Decentralization of the Cryptocurrency \n",
        "<br>\n",
        "dy/dx on the Ethereum Blockchain \n",
        "</h1>\n",
        "\n",
        "<h2 style=\"text-align: center;\">\n",
        "\n",
        "Alex Schaef, Nathaniel Hamilton Thompson, Orin Crouse\n",
        "\n",
        "</h2>\n",
        "\n",
        "<h3 style=\"text-align: center;\">\n",
        "\n",
        "# Abstract\n",
        "\n",
        "</h3>\n",
        "Cryptocurrency exchanges heavily emphasize being a “decentralized finance,” in that all transactions of cryptocurrencies are made between two individuals without requiring a central intermediary. However, recent studies have expressed doubt about the decentralized nature of cryptocurrency. In this paper, we study the Euler crypto token (in addition to a previous study done over the AAVE token) to conclude that, although there are some centralized components within the network of transactions, trends across multiple tokens still indicate a decentralized nature to the network.\n",
        "\n",
        "#1 Introduction\n",
        "\n",
        "Cryptocurrency prides itself on being a truly decentralized finance, meaning transactions can happen between any two individuals, or more, without the need of a central intermediary. In our lives, the best example of an intermediary is a bank. With the U.S. dollar, transactions are normally approved by a bank, meaning most exchanges of money go through a central point; the majority of transactions are between a person and a bank. Cryptocurrency is different in that transactions are made entirely between individuals, with no central intermediary. These transactions are recorded on a blockchain, which is essentially a virtual ledger. Our project is inspired by a previous paper written by Ziqiao Ao, Gergely Horvath, and Luyao Zhang, titled "Is Decentralized Finance Really Decentralized? A Social Network Analysis of the AAVE Protocol on the Ethereum Blockchain". The paper studies the AAVE token, and attempts to argue that cryptocurrency is not fully decentralized as it claims to be. In this project, we will expand on the studies done in this original paper, with the following goals:\n",
        "<ul>\n",
        "  <li>Confirm or deny the results of the original paper.<li>\n",
        "  <li>Use data from dy/dx token to expand on the results of the original paper.<li>\n",
        "  <li>Examine trends between tokens to see if the decentralization of transactions is comparable across different currencies.<li>\n",
        "  <li>Examine trends across time to see if different tokens follow a similar trend over the lifetime of the token.\n",
        "</ul>\n",
        "\n",
        "## 1.1 General Approach\n",
        "\n",
        "This notebook take the approach of taking the networks for the Euler token and re-framing the data into simpler, more readable outputs to better explain the idea of the centralization for the tokens. A quote to describe the idea used is\n",
        "\n",
        "\"core-periphery structure in its simplest form refers to a partition of a network into two groups of nodes called core and periphery, where core nodes are densely interconnected (i.e., adjacent), and peripheral nodes are adjacent to the core nodes but not to other peripheral nodes\".[2]\n",
        "\n",
        "\n",
        "If a token is to be described as being a central network we would see our graphs consist of core nodes, while a decentralized network would consist of periphery nodes.\n",
        "\n",
        "Core-periphery pairs are defined to have the properties of:\n",
        "\n",
        "$$\n",
        "A^*=A^*_{ij}=(x_i+x_j-x_ix_j)\\delta(c_i,c_j)\n",
        "$$\n",
        "We see $x_i=1$ for core nodes and $x_i=0$ for peripheral nodes. The index of the core-peripheral pair to which node $i$ belongs to is represented by $c_i(1 \\leq c_i \\leq C)$. The following properties are treated like axioms here.\n",
        "<ol>\n",
        "  <li> Every core node is adjacent to every other core node.</li>\n",
        "  <li>Every core node is adjacent to all corresponding peripheral nodes.</li>\n",
        "  <li>Every peripheral node is not adjacent to any other peripheral node.</li>\n",
        "  <li>Lastly, there are no edges between different idealized core-periphery pairs. $[3, 4]$</li>\n",
        "</ol>\n",
        "\n",
        "When computing you want $c_i,x_i \\in(1 \\leq i \\leq N)$ not be maximized comparatively between $A$ and $A*$. This is shown by:\n",
        "$$Q^{cp}_{config} = \\frac{1}{2M} \\sum_{i=1}^N\\sum_{j=1}^N A_{ij}A_{ij}^* - Ε [\\frac{1}{2M} \\sum_{i=1}^N \\sum_{j=1}^{conf}(1-A_{ij}^*)]$$\n",
        "Using a configuration model where the expected number of edges between nodes $i$ and $j$ can be represented by $Ε[A_{ij}^{conf}]=\\frac{d_id_j}{2M}$.\n",
        "\n",
        "\n",
        "# 3 Data\n",
        "\n",
        "In the section titled \"Construct Continuous Core-Periphery Structures\", various graphs are formed, each with different algorithms.\n",
        "\n",
        "## 3.1 Seeing the token's raw form of a network for the months of June through August, 3 continuous months.\n"
      ],
      "id": "e74bb0d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!pip install matplotlib==3.5.1 &> /dev/null\n",
        "#!pip install --upgrade scipy networkx &> /dev/null\n",
        "#!pip install cpnet &> /dev/null\n",
        "\n",
        "import cpnet\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import community.community_louvain as community\n",
        "from numpy import *\n",
        "import random\n",
        "import requests\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "print(\"The libraries used are: matplotlib (verison 3.5.1), scipy, networkx, cpnet, numpy, pandas, os, time, zipfile, tqdm,\")\n",
        "print(\"community.community_louvain, random, requests, json, and datetime.\")\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nghthompson/Math_Clinic_Project/main/Euler%20Crypto%20Data.csv'\n",
        "edf = pd.read_csv(url)\n",
        "# @title Refinement of Data\n",
        "\n",
        "#Number Wallet IDs for simplification\n",
        "\n",
        "unique_addresses = set(edf['from_address'].unique()) | set(edf['to_address'].unique())\n",
        "mapping = {address: n for n, address in enumerate(unique_addresses)}\n",
        "\n",
        "edf[['from_ID', 'to_ID']] = edf[['from_address', 'to_address']].replace(mapping)\n",
        "\n",
        "# edit timestamp to sort by days\n",
        "\n",
        "edf.rename(columns={'f0_':'value'}, inplace = True)\n",
        "edf = edf.dropna()\n",
        "edf['value'] = edf['value'].apply(lambda x: float(x))\n",
        "edf['timestamp'] = pd.to_datetime(edf['block_timestamp'])\n",
        "edf['timestamp'] = edf['timestamp'].apply(lambda x: str(x)[:10])\n",
        "edf['timestamp'] = pd.to_datetime(edf['timestamp'])\n",
        "\n",
        "# breakdown dataframe into weeks and months\n",
        "\n",
        "all_time = edf\n",
        "june = edf[(edf.timestamp >= '2022-06-01') & (edf.timestamp <= '2022-06-30')]\n",
        "july = edf[(edf.timestamp >= '2022-07-01') & (edf.timestamp <= '2022-07-31')]\n",
        "august = edf[(edf.timestamp >= '2022-08-01') & (edf.timestamp <= '2022-08-31')]\n",
        "week1 = edf[(edf.timestamp >= '2022-06-19') & (edf.timestamp <= '2022-06-25')]\n",
        "week2 = edf[(edf.timestamp >= '2022-06-26') & (edf.timestamp <= '2022-07-02')]\n",
        "week3 = edf[(edf.timestamp >= '2022-07-03') & (edf.timestamp <= '2022-07-09')]\n",
        "week4 = edf[(edf.timestamp >= '2022-07-10') & (edf.timestamp <= '2022-07-16')]\n",
        "week5 = edf[(edf.timestamp >= '2022-07-17') & (edf.timestamp <= '2022-07-23')]\n",
        "week6 = edf[(edf.timestamp >= '2022-07-24') & (edf.timestamp <= '2022-07-30')]\n",
        "week7 = edf[(edf.timestamp >= '2022-07-31') & (edf.timestamp <= '2022-08-06')]\n",
        "week8 = edf[(edf.timestamp >= '2022-08-07') & (edf.timestamp <= '2022-08-13')]\n",
        "week9 = edf[(edf.timestamp >= '2022-08-14') & (edf.timestamp <= '2022-08-20')]\n",
        "week10 = edf[(edf.timestamp >= '2022-08-21') & (edf.timestamp <= '2022-08-27')]\n",
        "\n",
        "all_time_g = nx.from_pandas_edgelist(edf, source='from_ID', target='to_ID', edge_attr='value')\n",
        "june_g = nx.from_pandas_edgelist(june, source='from_ID', target='to_ID', edge_attr='value')\n",
        "july_g = nx.from_pandas_edgelist(july, source='from_ID', target='to_ID', edge_attr='value')\n",
        "august_g = nx.from_pandas_edgelist(august, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week1_g = nx.from_pandas_edgelist(week1, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week2_g = nx.from_pandas_edgelist(week2, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week3_g = nx.from_pandas_edgelist(week3, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week4_g = nx.from_pandas_edgelist(week4, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week5_g = nx.from_pandas_edgelist(week5, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week6_g = nx.from_pandas_edgelist(week6, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week7_g = nx.from_pandas_edgelist(week7, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week8_g = nx.from_pandas_edgelist(week8, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week9_g = nx.from_pandas_edgelist(week9, source='from_ID', target='to_ID', edge_attr='value')\n",
        "week10_g = nx.from_pandas_edgelist(week10, source='from_ID', target='to_ID', edge_attr='value')"
      ],
      "id": "bd24e801",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_comm = nx.community.label_propagation_communities(all_time_g)\n",
        "community_index = {n: i for i, com in enumerate(all_comm) for n in com}\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.title('Network Graph'.format(len(all_time.index)))\n",
        "all_color = [community_index[n] for n in all_time_g]\n",
        "print(len(all_time.index), 'Number Transactions for the entire data set')\n",
        "nx.draw(all_time_g, with_labels=False, node_size=13, node_color=all_color)"
      ],
      "id": "377fcb7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "june_comm = nx.community.label_propagation_communities(june_g)\n",
        "community_index = {n: i for i, com in enumerate(june_comm) for n in com}\n",
        "\n",
        "plt.figure(figsize=(10 , 10))\n",
        "plt.title('{:} Euler Transactions (June 2022)'.format(len(june.index)))\n",
        "june_color = [community_index[n] for n in june_g]\n",
        "print(len(june.index), 'Number Transactions for June')\n",
        "nx.draw(june_g, with_labels=False, node_size=5, node_color=june_color)"
      ],
      "id": "970a63a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.scatter(june['timestamp'], june['to_ID'])\n",
        "plt.title('Buyer Transactions (June 2022)'.format(len(june.index)))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(june['from_ID'], june['to_ID'])\n",
        "plt.title('Seller Transactions (June 2022)'.format(len(june.index)))\n",
        "\n",
        "plt.tight_layout()"
      ],
      "id": "8b2804d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#title Sorting and Defining Core-Periphery Structure\n",
        "\n",
        "edf.sort_values('block_timestamp', ascending = True)\n",
        "\n",
        "# data cleaning\n",
        "\n",
        "edf = edf[edf['timestamp']>='2021-12-30']\n",
        "edf = edf[edf['timestamp']<='2022-08-24']\n",
        "\n",
        "\n",
        "edf.to_csv('Euler Raw Transfer Data.csv')\n",
        "\n",
        "edf = edf.drop(columns = ['token_address','block_timestamp'])\n",
        "\n",
        "## add values between the 2 same addresses together\n",
        "edf[['from_address', 'to_address']] = np.sort(edf[['from_address', 'to_address']], axis=1)\n",
        "edf= edf.groupby(['timestamp','from_address','to_address']).agg(lambda x: sum(x)).reset_index()\n",
        "edf.to_csv('Euler transaction data_after preprocessing.csv')\n",
        "edf = pd.read_csv('Euler transaction data_after preprocessing.csv')\n",
        "\n",
        "##Network Analysis\n",
        "\n",
        "edf_time_partition= edf.groupby(['timestamp'])['to_address'].agg(['nunique']).reset_index()\n",
        "edf_time_partition = edf_time_partition.drop(['nunique'], axis=1)\n",
        "\n",
        "##Number of daily edges\n",
        "\n",
        "num_nodes = []\n",
        "num_edges = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of Number of nodes, number of edges\n",
        "    nodes = G.number_of_nodes()\n",
        "    edges = G.number_of_edges()\n",
        "    num_nodes.append(nodes)\n",
        "    num_edges.append(edges)\n",
        "\n",
        "    Network_Features={\"num_nodes\" : num_nodes,\"num_edges\" : num_edges}\n",
        "Network_Features=pd.DataFrame(Network_Features)\n",
        "Network_Features['time'] =  edf_time_partition['timestamp']\n",
        "\n",
        "### Degree Setting\n",
        "\n",
        "Degreemean = []\n",
        "Degreestd = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    #edf_1 = actsenrec.loc[actsenrec['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of Degree_centrality, mean_value\n",
        "    degrees = G.degree()\n",
        "    degree = list(dict(G.degree()).values())\n",
        "    edf_deg = {\"Degree\" : degree}\n",
        "    edf_deg = pd.DataFrame(edf_deg)\n",
        "    DC_mean = edf_deg['Degree'].mean()\n",
        "    DC_std = edf_deg['Degree'].std()\n",
        "    Degreemean.append(DC_mean)\n",
        "    Degreestd.append(DC_std)\n",
        "\n",
        "Network_Features['Degree mean']  = Degreemean\n",
        "Network_Features['Degree std']  = Degreestd\n",
        "\n",
        "##Extract Top 10 by ratio\n",
        "\n",
        "top10Degreemean = []\n",
        "top10Degreestd = []\n",
        "\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    sender_mdegree= edf_1.groupby(['from_address'])['to_address'].count().reset_index()\n",
        "    receiver_mdegree = edf_1.groupby(['to_address'])['from_address'].count().reset_index()\n",
        "    sender_mdegree = sender_mdegree.rename(columns={'to_address':'degree'})\n",
        "    sender_mdegree = sender_mdegree.rename(columns={'from_address':'address'})\n",
        "    receiver_mdegree = receiver_mdegree.rename(columns = {'from_address':'degree'})\n",
        "    receiver_mdegree = receiver_mdegree.rename(columns = {'to_address':'address'})\n",
        "\n",
        "    merge = pd.merge(sender_mdegree,receiver_mdegree,on=\"address\",how = \"outer\")\n",
        "    merge = merge.fillna(int(0))\n",
        "    merge['degree'] = merge['degree_x']+merge['degree_y']\n",
        "\n",
        "    merge.sort_values(by=['degree'], ascending=False, inplace=True)\n",
        "    merge = merge.reset_index()\n",
        "    top5degree = merge['address'][0:10].tolist()\n",
        "\n",
        "    sen_top =  edf_1[edf_1['from_address'].isin(top5degree)]\n",
        "    rec_top= edf_1[edf_1['to_address'].isin(top5degree)]\n",
        "\n",
        "    topaddress = pd.concat([sen_top,rec_top]).drop_duplicates()\n",
        "\n",
        "    G = nx.from_pandas_edgelist(topaddress, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    # Calculation of absolute degree\n",
        "    degree = []\n",
        "    for j in range (0,2): ## MUST CHANGE BACK TO (0,10) LATER. FIND OUT WHY top5degree IS ONLY THREE VARIABLES\n",
        "        degrees = G.degree(top5degree[j])\n",
        "        degree.append(degrees)\n",
        "    edf_deg = {\"Degree\" : degree}\n",
        "    edf_deg = pd.DataFrame(edf_deg)\n",
        "    deg_mean = edf_deg['Degree'].mean()\n",
        "    deg_std = edf_deg['Degree'].std()\n",
        "    top10Degreemean.append(deg_mean)\n",
        "    top10Degreestd.append(deg_std)\n",
        "\n",
        "Network_Features['Top10Degree mean']  = top10Degreemean\n",
        "Network_Features['Top10Degree std']  = top10Degreestd\n",
        "\n",
        "Network_Features['Top10 Degree mean ratio']  = Network_Features['Top10Degree mean']/Network_Features['Degree mean']\n",
        "\n",
        "#The above code cells don't show much being there aren't 10 degrees found, but rather only two.\n",
        "#That means there are only two core nodes that reach the criteria to be considered core.\n",
        "#Already we see the Euler token to be more decentralized rather than central.\n",
        "\n",
        "### Degree centrality\n",
        "DCmean = []\n",
        "DCstd = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    #edf_1 = actsenrec.loc[actsenrec['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of Degree_centrality, mean_value\n",
        "    deg_cen = nx.degree_centrality(G)\n",
        "    edf_deg = pd.DataFrame.from_dict(deg_cen, orient='index', columns=['Degree_Centrality'])\n",
        "    DC_mean = edf_deg['Degree_Centrality'].mean()\n",
        "    DC_std = edf_deg['Degree_Centrality'].std()\n",
        "    DCmean.append(DC_mean)\n",
        "    DCstd.append(DC_std)\n",
        "\n",
        "#The above code cell redefines the core nodes found to double check and ensure the understanding of core is reached for the entire network.\n",
        "\n",
        "### Coefficient Clusters\n",
        "\n",
        "clustermean = []\n",
        "clusterstd = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    #edf_1 = actsenrec.loc[actsenrec['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # Unweighted-Directed Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of Clustering_Coefficient, mean_value, std\n",
        "    clustering = nx.clustering(G)\n",
        "    df_cluster = pd.DataFrame.from_dict(clustering, orient='index', columns=['Clustering_Coefficient'])\n",
        "    cluster_mean = df_cluster['Clustering_Coefficient'].mean()\n",
        "    cluster_std = df_cluster['Clustering_Coefficient'].std()\n",
        "    clustermean.append(cluster_mean)\n",
        "    clusterstd.append(cluster_std)\n",
        "\n",
        "#The above code cell is form the cluster by coefficient. This is for both core and periphery\n",
        "\n",
        "### Build Modularity\n",
        "\n",
        "mod_list = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    #edf_1 = actsenrec.loc[actsenrec['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # unweighted-undirected Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of modularity\n",
        "    part = community.best_partition(G)\n",
        "    mod = community.modularity(part,G)\n",
        "    mod_list.append(mod)\n",
        "\n",
        "    ### Build Transitivity\n",
        "\n",
        "    tran_list = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    #edf_1 = actsenrec.loc[actsenrec['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # Unweighted-undirected Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of transitivity,\n",
        "    tran = nx.transitivity(G)\n",
        "    tran_list.append(tran)\n",
        "\n",
        "### Centrality by Eigenvector\n",
        "\n",
        "eigmean = []\n",
        "eigstd = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    #edf_1 = actsenrec.loc[actsenrec['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of Closeness_centrality, mean_value\n",
        "    eig_cen = nx.eigenvector_centrality(G, max_iter=20000)\n",
        "    edf_eig = pd.DataFrame.from_dict(eig_cen, orient='index', columns=['eigenvector_centrality'])\n",
        "    eig_mean = edf_eig['eigenvector_centrality'].mean()\n",
        "    eig_std = edf_eig['eigenvector_centrality'].std()\n",
        "    eigmean.append(eig_mean)\n",
        "    eigstd.append(eig_std)\n",
        "\n",
        "### Core Count\n",
        "core_cnt = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "    coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "    core = coredf[coredf['coreness']==1].index.tolist()\n",
        "    cnt = len(core)\n",
        "    core_cnt.append(cnt)\n",
        "\n",
        "### Closeness Centrality\n",
        "\n",
        "CCmean = []\n",
        "CCstd = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "\n",
        "    # Data Partition\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "\n",
        "    # MultiDi Network Building (weighted-directed graph)\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "    # Calculation of Closeness_centrality, mean_value\n",
        "    close_cen = nx.closeness_centrality(G)\n",
        "    edf_close = pd.DataFrame.from_dict(close_cen, orient='index', columns=['Closeness_Centrality'])\n",
        "    CC_mean = edf_close['Closeness_Centrality'].mean()\n",
        "    CC_std = edf_close['Closeness_Centrality'].std()\n",
        "    CCmean.append(CC_mean)\n",
        "    CCstd.append(CC_std)\n",
        "\n",
        "### Number of components\n",
        "\n",
        "components_cnt = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    com_cnt = nx.number_connected_components(G)\n",
        "    components_cnt.append(com_cnt)\n",
        "\n",
        "### Gaint component by size and number of nodes\n",
        "\n",
        "giant_com_ratio = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "# G = nx.Graph()\n",
        "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "    G0 = G.subgraph(Gcc[0])\n",
        "#com_cnt = nx.number_connected_components(G)\n",
        "#components_cnt.append(com_cnt)\n",
        "    nodes = G0.number_of_nodes()\n",
        "    nodes_whole = G.number_of_nodes()\n",
        "    ratio = nodes/nodes_whole\n",
        "    giant_com_ratio.append(ratio)\n",
        "\n",
        "### Save features output\n",
        "\n",
        "Network_Features['DCmean']=DCmean\n",
        "Network_Features['DCstd']=DCstd\n",
        "Network_Features['clustermean']=clustermean\n",
        "Network_Features['clusterstd']=clusterstd\n",
        "Network_Features['modularity']=mod_list\n",
        "Network_Features['transitivity']=tran_list\n",
        "Network_Features['eig_mean']=eigmean\n",
        "Network_Features['eig_std']=eigstd\n",
        "Network_Features['closenessmean']=CCmean\n",
        "Network_Features['closenessstd']=CCstd\n",
        "Network_Features['Components_cnt']=components_cnt\n",
        "Network_Features['giant_com_ratio']=giant_com_ratio\n",
        "Network_Features['core_cnt']=core_cnt\n",
        "Network_Features['top10Degreemean']=top10Degreemean\n",
        "Network_Features['top10Degreestd']=top10Degreestd\n",
        "Network_Features['core_cnt']=core_cnt\n",
        "\n",
        "Network_Features['token'] =  'Euler'\n",
        "#Network_Features\n",
        "\n",
        "Network_Features.to_csv('Euler_Network_Features.csv')"
      ],
      "id": "7e47655d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construction of the continuous core-periphery structure using the Borgatti-Everett Algorithm. \n"
      ],
      "id": "2afb86bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#title Borgatti-Everett Algorithm\n",
        "\n",
        "edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][63]]\n",
        "G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "\n",
        "\n",
        "alg = cpnet.BE()\n",
        "alg.detect(G)\n",
        "c = alg.get_pair_id()\n",
        "x = alg.get_coreness()  # Get the coreness of nodes\n",
        "\n",
        "##coreness = pd.DataFrame.from_dict(x, orient='index', columns=['Coreness'])\n",
        "##corenessmean = coreness['Coreness'].mean()\n",
        "#corenessmean\n",
        "\n",
        "#sig_c, sig_x, significant, p_values = cpnet.qstest(\n",
        "#    c, x, G, alg, significance_level=0.05, num_of_rand_net=100, num_of_thread=16)\n",
        "\n",
        "#print(significant)\n",
        "#print(p_values)\n",
        "\n",
        "pos = nx.spiral_layout(G,scale = 1)\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = plt.gca()\n",
        "ax, pos = cpnet.draw(G, c, x, ax, pos = pos)\n",
        "\n",
        "edf_2 = edf_1[['from_address', 'to_address', 'value']]\n",
        "#edf_2.tail()\n",
        "result = edf_2.dtypes\n",
        "#print(result)\n",
        "seller = edf_2.from_address.unique()\n",
        "buyer = edf_2.to_address.unique()"
      ],
      "id": "d75ddfbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We continue with the Kojaku-Masda Algorithm to see a similar approach, but better given colors....\n"
      ],
      "id": "e522585b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "kmconfig = cpnet.KM_config()\n",
        "kmconfig.detect(G)\n",
        "\n",
        "pos = nx.spiral_layout(G,scale = 1)\n",
        "c = kmconfig.get_pair_id()\n",
        "x = kmconfig.get_coreness()\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = plt.gca()\n",
        "ax, _ = cpnet.draw(G, c, x, ax, pos = pos)"
      ],
      "id": "d58efc58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Conform Core Addresses by Date Counts\n",
        "core_address = []\n",
        "a = 0\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "    coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "    core = coredf[coredf['coreness']==1].index.tolist()\n",
        "    core_address.extend(core)\n",
        "    a+=1\n",
        "    #print(a)\n",
        "\n",
        "cores = pd.DataFrame(core_address)\n",
        "core_cnt = cores[0].value_counts(ascending=False).reset_index()\n",
        "#core_cnt\n",
        "\n",
        "core_cnt.to_csv('core_date_cnt.csv')\n",
        "\n",
        "\n",
        "#Number of Core Members Each Day\n",
        "core_cnt = []\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][i]]\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "    coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "    core = coredf[coredf['coreness']==1].index.tolist()\n",
        "    cnt = len(core)\n",
        "    core_cnt.append(cnt)\n",
        "\n",
        "#Average Number of Neighbors of Cores\n",
        "\n",
        "avg_core_neighbor = []\n",
        "\n",
        "for i in range(0,len(edf_time_partition)):\n",
        "    edf_1 = edf.loc[edf['timestamp']==edf_time_partition['timestamp'][0]]\n",
        "    G = nx.from_pandas_edgelist(edf_1, 'from_address', 'to_address', 'value', nx.Graph())\n",
        "    alg = cpnet.BE()\n",
        "    alg.detect(G)\n",
        "    c = alg.get_pair_id()\n",
        "    x = alg.get_coreness()\n",
        "\n",
        "coredf = pd.DataFrame.from_dict(x, orient='index',columns=['coreness'])\n",
        "core = coredf[coredf['coreness']==1].index.tolist()\n",
        "\n",
        "neighbor_cnt = []\n",
        "for i in range (0,len(core)):\n",
        "    neighbor = G.degree(core[i])\n",
        "    neighbor_cnt.append(neighbor)\n",
        "\n",
        "neighbor_cnt_mean = mean(neighbor_cnt)\n",
        "avg_core_neighbor.append(neighbor_cnt_mean)\n",
        "\n",
        "print(\"Average Neighbors to Cores\", np.sum(neighbor_cnt_mean))\n",
        "\n",
        "\n",
        "#Network Dynamics NEED TO FILL IN THE REMAINING, last graph\n",
        "\n",
        "edf_2 = pd.read_csv('Euler_Network_Features.csv')\n",
        "\n",
        "fig,axes = plt.subplots(3,2)\n",
        "plt.style.use('default')\n",
        "#plt.style.use('seaborn-pastel')\n",
        "ax = edf_2[['Components_cnt']].plot(ax = axes[0,0], figsize=(10,10), grid=False, title='Number of components',xlabel=' ')\n",
        "ax.set_yscale('log')\n",
        "edf_2[['giant_com_ratio']].plot(ax = axes[0,1], figsize=(10,10), grid=False, title='Giant component size ratio',xlabel=' ')\n",
        "edf_2[['modularity']].plot(ax = axes[1,0], figsize=(10,10), grid=False, title='Modularity',xlabel=' ')\n",
        "#edf_2[['relative_degree']].plot(ax = axes[1,0], figsize=(13,10), grid=False, title='Relative degree',xlabel=' ')\n",
        "edf_2[['DCstd']].plot(ax = axes[1,1], figsize=(10,10), grid=False, title='Std of Degree Centrality',xlabel=' ')\n",
        "#edf_2[['cp_test_pvalue']].plot(ax = axes[2,0], figsize=(13,11), grid=False, title='p-value of cp test',xlabel=' ')\n",
        "edf_2[['Top10 Degree mean ratio']].plot(ax = axes[2,0], figsize=(10,10), grid=False, title='Top10 nodes avg degree / general avg degree',xlabel=' ')\n",
        "edf_2[['core_cnt']].plot(ax = axes[2,1], figsize=(10,10), grid=False, title='Number of cores',xlabel=' ')\n",
        "#edf_2[['giant_com_ratio']].plot(ax = axes[2,1], figsize=(13,10), grid=False, title='Giant component size ratio',xlabel=' ')\n",
        "\n",
        "plt.subplots_adjust(wspace =0.15, hspace =0.35)"
      ],
      "id": "86bfb394",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##3.2 Breakdown\n",
        "\n",
        "**Number of Components**: We expect a *smaller* number of componenets to indicate a more *centralized* network. The number of components is fairly random with an exception toward the beginning of the recorded data.\n",
        "\n",
        "**Giant Component Size Ratio**: A *larger* giant component size ratio indicates a more *centralized* network. In our data, the giant component ratio starts high (suggesting more centralization early on), then becomes random, similar to the number of components.\n",
        "\n",
        "**Modulatiry**: A *smaller* modularity score suggests a more *centralized* network. Modularity for the Ether token starts low, but quickly rises, and stays fairly stable past day 15. This indicates a more centralized network in early days that becomes decentralized and stays decentralized after a couple of weeks. However, while the modularity for Euler settles around 0.6, the modularity for the AAVE token (found in the original paper) settles around 0.8 before dropping down to 0.7, a possible indication that AAVE is more decentralized than Euler.\n",
        "\n",
        "**Standard Deviation of Degree Centrality**: A *higher* standard deviation suggests a more *centralized* network. Standard deviation for Euler starts high but quickly falls by day five, where is stays steady. Like the modularity scores, this suggests a more centralized network early on that quickly becomes and stays decentralized.\n",
        "\n",
        "\n",
        "#4 Conclusion\n",
        "\n",
        "While the prior study on the AAVE token suggested that there was a high level of centralization, our study with the Euler token does **not** indicate a centralized finance network. However, the tokens have similar trends in decentralization over time. Both tokens begin incredibly centralized, which should not be surprising since most tokens start from one central source. Over a few weeks, all tokens see an increase in the level of decentralization before eventually settling at a point that is certainly decentralized by definition, although both tokens’ networks maintain centralized aspects. This is most visible in the network graphs, where one account has edges linked to a noticeably large number of other accounts. However, the graphs change over time to reflect trends we see in other variables studied (number of components, giant component size ratio, standard deviation of degree centrality, modularity), in that all tokens’ trading networks are centralized when the tokens are created, but become decentralized a short time after trading begins.\n",
        "\n",
        "Personal takeaways from this project include getting a wider understanding of cryptocurrency trading and decentralized finance, utilizing graph theory to visualize trade networks, using data to study changes over time, and applying mathematical concepts to real world data.\n",
        "\n",
        "We hope our reults help our sponsor (Chainpulse) better understand the transaction networks they study on the Ethereum blockchain so that they can better develop their own research and analytics of cryptocurrency trading.\n",
        "\n",
        "#5 Citiations\n",
        "\n",
        "Ao, Ziqiao, Gergely Horvath, and Luyao Zhang. \"Is decentralized finance really decentralized? A social network analysis of the Aave protocol on the Ethereum blockchain.\" arXiv preprint arXiv:2206.08401 (2022). [1] <br>\n",
        "Kojaku, Sadamori, and Naoki Masuda. \"Core-periphery structure requires something else in the network.\" New Journal of physics 20.4 (2018): 043012. [2]"
      ],
      "id": "f6cf0bf0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}